---
layout: post
title:  "Benefits and limitations of using AI in design research"
author: Morna
categories: [ Research ]
tags: [ AI, methods ]
image: assets/images/firekids.jpg
rating: 4.5
---

## Are we living in a post-critical world?

> I do fear that we will have decades of misapplication and wasted brainpower studying the wrong problems where simple logic would be a better alternative when applied using the question of WHY to dive deeper and deeper into our understanding of causalities before blindly applying AI

([Book review by JC on Amazon](https://www.amazon.com/gp/customer-reviews/ R11XGS7UVMTE55/ref=cm_cr_dp_d_rvw_ttl?ie=UTF8&ASIN=046509760X))

AI can help you to increase productivity, improve the quality of your work and help you to meet tight deadlines. It can be (and is being) used throughout the design cycle for research, design, and writing. It is exceptionally good at crunching large data-sets and so holds the promise of making those mundane and repetitive tasks obsolete... Bring it on! Hallelujah!

Having tested AI out for a number of tasks my recommendation would be to use it as a starting point. Generative AI is great at giving you some rough drafts, but should not be relied on for quality. That needs an expert (in this case a design researcher) at the helm to write prompts that retrieve the right information; complete tasks by critiquing the results, and edit and augment outputs with human insights and knowledge.

This NNg article by Kate Moran and Jakob Nielsen (Nov 3rd 2023) gives [great advice on getting started.](https://www.nngroup.com/articles/ai-ux-getting-started/)

AI is incredibly powerful and useful, but a word of warning before you embrace AI blindly... I have personally worked on an AI project where the project team had not gone out to users to find out what their problem was. Instead they worked on a business OKR - a problem defined by management. It turned out they asked the wrong question... Fair enough in a fast-paced, test and learn environment... but god help you if you have spent months on the project.

## AI, what is it good for?

The important thing to understand about AI is that it is an aggregator that data-crunches the
information you give it (or define), and creates correlations based on that information. This is a reductive process.

While you can amuse yourself with the similarities of the process used by GANS, and the theory of the Bicameral Mind (Julian Jaynes ), AI is still an unsophisticated processor compared to the human mind.

Rule number one is that crapola in, means crapola out. This matters as much for creating prompts that will elicit the right information as the data it crunches.

Prompt writing is a skill in itself that requires some knowledge of the particular software you are using, and subject area expertise. Even with this knowledge AI can give vague and inaccurate results and you may need to iterate the prompt to get the results you need. I’m cynical about developing a prompt library for research, as if anything is that generic, it might just be easier to develop a template for the output. In many cases, any work-arounds you try may be less efficient than your existing processes.
   
The data available to crunch also presents problems. We have all had that one friend create a prompt featuring a man and his car, which resulted in a naked woman sprawled across his car. ts hard not to pornify images with AI. This is perhaps a damning inditement of society... but definitely damning of the images available on the internet. Extrapolating out from this... bias in AI is both inevitable and well documented, and has led to a widespread public debate around ethics in relation to structural sexism, racism, and most other ‘isms”... (except Impressionism as far as I can tell).

Alongside the bias, you may be served a decent helping of (unmarked) hypothetical answers, or worse... hallucinations. So, be sure to ask for references... and validate the information it gives you.

AI’s research tools are not able to observe users, or to infer anything based on observation. The most glaring problem with AI analysis for design research, is the inability to bring contextual information into the equation. This means that the current AI tools that claim to be able to provide insights are quite often, simply wrong.

“AI-derived design critiques are dangerous because many of its insights are wrong”
[(NNG article by Kate Moran and Jakob Nelson)](https://www.nngroup.com/articles/ai-ux-getting- started/)

## AI in discovery research

This article is a long read. It walks you through my design research process as a problem space researcher and where and how I see AI being a useful contributor to the project.

Working in discovery means that I spend most of my efforts in the very early stages of the design cycle exploring the big _WHYs_ in user interviews. It is really my job to find out what problems the user wants to solve ideally _BEFORE_ the team start working on detailed designs. I spend less time doing things like unmoderated user testing, or fast paced test and learn that you might see in an organisation that has embraced Design Sprints. Market research and competitor analysis are not usually part of my remit - so tools like personas are not used.

It matters where and how you implement AI solutions into your design process. It is important to consider the purpose of each step in the process, and not to sacrifice engagement with the wider project team, for the sake of efficiency. As a researcher the aim is to be the voice of the user, as everyone knows. It is also to guide and encourage designers and stakeholder while making the best of their expertise.

## Security First

A significant barrier to using these tools for research at any stage, but particularly with participant information, is the sharing of proprietary information and GDPR sensitive data. Technical and organisational measures must be in place to ensure data sources aren’t merged.

If tools are built specifically for research, and researchers have permission to use them, then we can expect them to have been security checked and compliant. Tools like ChatGPT are not. OpenAI’s data policy states the following:

**“In certain circumstances we may provide your personal information to third parties without further notice to you, unless required by the law.”**

Using a third party piece of AI software, especially when processing sensitive GDPR data, is likely to be breaking both policy, and the law. Please ensure the products you use have been passed by security and you have permission to use them for research purposes.

## Kick-off & Framing the Research Study

At the early stages of researchers solicit briefings from senior stakeholders so that they are clear on the objectives of the task. I often only get visibility of a specific journey or journey fragment, on a digital channel and not a full end-to-end service. For this it is easier and probably better to run individual interviews with stakeholders rather than have a kick-off session (which is aimed more at end-to-end services)

For individual interviews an AI tool like Otter.ai would be useful to transcribe each interview and can be set up to capture decisions and action points. For a service design kick-off, a tool like Miro.com or Figjam would be useful to capture and analyse each stakeholders’ perspective and get a full understanding of the service journey. This requires a good deal of user input, but AI tools could be useful for aggregating output in thematic analysis for items like key pain-points.

### Secondary Research

In my role, as a discovery space (or problem space) user researcher, secondary research (or desk- research) is where AI can currently shortcut a lot of manual and tedious human-work and provide high quality results. There is a good deal of overlap between this and defining the research, so I often carry out these steps at the same time.

If I am asked to explore a particular domain area such as attitudes to AI, I can quickly identify high level findings at a global level. Initial exploration might be better carried out in dialogue with ChatGPT.ai which is suited for open-ended, weak-structured, or confusing questions. It would be useful to switch over to Perplexity.ai when specific questions have been identified. Perplexity is more adept than ChatGPT at finding answers to clear and specific questions with a clear intent, making it better suited for factual queries and structured information. It also provides more up to date information gathered from a range of sources that are properly referenced, whereas ChatGPT often produces vague results and cannot pinpoint references even when they were requested.

It’s important to note that AI software cannot access proprietary information, unless there is a license agreement. However, an up-to-date AI like Perplexity can direct researchers to the most recent and highly ranked articles or publications to complete the research. In my work scenarios, the cost of proprietary research, and time pressures to meet deadlines- as well as the importance of testing your specific products with your specific customers - mean that web-based desk research is often good enough, even when it’s a little out of date.

### Review Customer Journey

This phase in the project will include reviewing the product (either a user journey or a segment of the journey). This is a manual task that involves deep discussion with designers while doing a “walk-through” of the different pathways. It may be useful to video and transcribe this (Teams or Otter.ai may be useful)- but I suspect that it adds work to the process rather than offers and efficiency.

## Research Plan and Documentation

### Present research and research plan

Presenting insights from desk research at this stage often includes identifying weaknesses and gaps, and defining the high level research questions to be carried into the project. The desk research, a review of any software or service that needs tested, and discussions with stakeholders to clarify the objectives often mean that the research design is iterative and AI intervention is more likely to be a distraction to getting the work done than provide benefits.

Where AI might be useful is in auto-generating visuals to present the information to stakeholders. Beautiful.ai and Decktopus.ai both generate AI visual responses to prompts, direct to slide. This is a really useful feature that minimises task switching, meaning you can stay focused on articulating insights, and could make you more efficient and able to meet harsh deadlines. It can also help you develop some really impressive and persuasive presentations

### Formal documents

Once you have sign off on the research plan, it will usually needs to be documented for governance and an audit trail. It includes formal documents like:

- The research plan
- Consent forms
- Participant recruitment

(Depending on the maturity of your organisation and the participants you need for the project other documents like an ethics plan and participant outreach might be needed.)

In my role these are normally templated and I only have to input the details of the project. When I have had to write these documents I have used Grammarly and Hemingway to ensure that the reading age is appropriate and inclusive. Others might find ChatGPT, Perplexity or another AI writing tool (Decktopus, Hyperwriteai, and Gemini etc) might help summarise information.

## Doing Primary Research

### Moderating Tests

Discovery often requires deep listening and engaging with the user at a human level. It also benefits from observing users as they engage with and interact with software. This means researchers can elicit user feedback as they go about the task in alignment with the project needs. It is not something that we can automate with AI, yet.

### Capturing test information

Video recording and transcribing software can capture video and autogenerated transcripts. Teams is my go to in a corporate, and is really good at understanding people regardless of accent and dialect, proving invaluable in a research setting.

Getting buy-in for research and socialising findings can be hard. If stakeholders have objections to the research (and they often do) getting stakeholder engagement during the interviews is critical. They will often be shocked when they watch a customer wrestling with the software, and that will turn them into a champion of user research. Stakeholders also bring a wealth of knowledge about the business, the domain area and subject specific expertise. So it is important to ask them to take notes on each user interview, and offer insights on what can flex in the hands of designers.

I’d like to say we capture stakeholder insights in a tool like Miro, or Figjam but stakeholders often come from across the organisation and don’t have access to design tools. In some design teams we can delegate capturing the information, but I find open discussion (without video), encourages everyone to participate and allows the conversation to flow more easily. I also encourage sharing notes in a research chat channel (like Teams) for visibility immediately after the interviews.

### Analysis Insight Generators and AI collaborators

The authors of the NNG article ["AI-Powered Tools for UX Research: Issues and Limitations” 02-July-2023](https://www.nngroup.com/articles/ai-powered-tools-limitations/) identify two types of research analysis tools:
- Insight Generators and
- AI Collaborators

Overall, the authors emphasize that while AI-driven tools hold promise for enhancing research efficiency and quality in the future, current tools fall short due to usability issues, lack of contextual understanding, premature development, and an inability to prioritize insights effectively.

Researchers and designers need to dive deep into the question of “WHY” a problem exists. To borrow heavily from Pearl in “Why Science: The book of cause and effect.”: “the problem is that AI tries to predict upward from correlations... [In user research, researchers...] must down determine why a problem exists and the assumptions around that cause, not predict blindly from a lack of understanding of the underlying system's interrelationships.”.
 
The key issue with AI analysis tools is that they data-crunch the transcript and generalise up the way, which results in bland results that lack credibility.

There are 4 key issues that need addressed for AI analysis to become really useful to researchers like me:

1. Lack of Contextual Understanding: Unlike human researchers, Insight Generators cannot factor in context as they cannot accept various types of information from researchers. This limitation impacts the quality and relevance of generated insights.
2. Premature Development: They lack maturity in handling user-research data, providing limited capabilities such as generating only a list of top insights and don’t yet have the ability to modify prompts or ask follow-up questions.
3. Inability to Prioritize: Without an understanding of study goals, these tools could not prioritize insights effectively, presenting themes without any order of importance. This limitation further diminishes the value and relevance of the generated analysis.
4. Usability and Performance Issues: The tools tested in the study exhibited outages, errors, and unstable performance, requiring multiple interactions with customer support to access basic features. These issues hindered the analysis process rather than expediting it.

The authors note that Insight Generators are less effective than collaborators, because of the “one and done” approach to data input.

According to NNG, AI collaborators (like ChatGPT and Gemini) are more sophisticated, as they can accept information from multiple sources such as researchers’ and stakeholders’ notes. This means they can create themes and insights based on input from contextual sources. With the right prompts they can also produce visuals, e.g., “What were the users’ frustrations? Visualize with a bar chart.”

This sounds like it may be useful - almost like having an extra team member - and I particularly like the ease with which you can visualise data - but I have not tested this with real research materials.

Understanding the constraints of the system is key to getting the maximum benefit, so lets run it through... A problem with testing is that the standard hour long interview would use up 13,950 tokens (according to ChatGPT’s OpenAI's models). This exceeds the limits of most conversational models, and means that the researcher would have to select and input just parts of the transcript, parts of the contextual information and parts of the stakeholder notes. Even highly edited versions could more than double the initial 13K tokens.

There is a good deal of editing in that, and it sounds like a lot of to-ing and fro-ing, as you input segments of research information to build a whole picture. Whether this will be as accurate, or insightful as humans, is yet to be seen. It does sound a lot less efficient.

IMHO, when stakeholders are engaged in note-taking, the aggregation of their notes, normally does a pretty good job of summarising the insights for each session. Like all researchers I review, do secondary research to supplement findings and “get into the flow” to come up with the final insights. So even with this research support there is usually more work to be done.

## Design workshops and hand-off

I’ve had the exceptionally good experience working with expert designers, and have found design workshops are the best way to bring insights together, make the best of the expertise in the room and formulate plans going forwards.

I’ve developed user needs for some organisations where a detailed audit trail is needed. However, I’ve found designers are often resistant to these as they can be overwhelming, and overly prescriptive, putting unnecessary constraints on the project and slowing down useful work.

At this stage I would use Miro or Figjam to capture information and ensure that stakeholders are on the same page, and designers are clear about how they are balancing their design problems.

It could be useful to get a collaborative AI to suggest How Might We’s and suggest relevant features- but I would do this as a sense check, to compliment the work of the team.

## Final Presentation

The final presentation is usually directed towards senior stakeholders and should focus on telling the story of the research rather than auditing insights. Ideally this deck should reflect the current state (meaning the live state), the challenges faced by customers, along with any major insights and finish with either the future state (new design), or the redefined design brief and next steps.

Professional, eye catching impactful slides really matter. So I might combine a few AI tools to create this and would definitely benefit from something like Decktopus or Beautiful.ai to limit task switching and keep me focused on the message.

## Conclusions

There’s a raft of AI software that could be useful to discovery research. The first organisations that can ensure compliance and develop an end to end process for using these in research, could save shed loads of time and effort.

However, AI is a very shiny thing! Managers need to be beware of magpies, and consider the placement and purpose of each step in the research design process and if and when AI might offer a hindrance rather than a help. Critical thinking is vital. It is easy to be lazy, but it is far easier to tired and overworked. That is when mistakes are made. 

A combination of these could be the perfect storm where costly business mistakes are made.
